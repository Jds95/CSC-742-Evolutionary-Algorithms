\documentclass{article}
\usepackage[utf8]{inputenc}

\title{An Evolutionary Computing Approach Toward the Lemmatization of Textual Data}
\author{Jesse Simpson, Amber Gillenwaters, Rafail Islam}
\date{December 2019}

\usepackage{natbib}
\usepackage{graphicx}

\begin{document}

\maketitle

\section{Introduction}

The need for an increased understanding of the analysis of natural language processing is universal in scope and potential utility. Businesses examine linguistic data to gain insights in meeting the needs of customers. Models of language classification contribute to the design of assistive technologies and teaching methods for individuals that may experience difficulties in reading, writing, visual or auditory comprehension, or in speech production. Evidence suggests that human communication shares characteristics in terms of neural processing regardless of language. Grammatical and semantic properties of words are an essential aspect of all linguistic models. Modeling natural language processing poses a variety of unique challenges. Recent increases in data accessibility, computational power, and innovation in strategy toward textual data manipulation has led to exponential growth and advancement in this topic area. This has contributed to increased demand for methodological development to improve upon existing theory and approaches. 

\section{Related Works}

Assessing the latest methods in language research is a major challenge in itself. The rapid increase in demand has led to fragmentation within the field, with developers often generating highly specified or proprietary solutions without contributing to open-source tools \citep{landset2015survey}. There is no standardization in industry in testing the efficacy of existing methods \citep{landset2015survey}. One manner in which data management strategies can be considered is in terms of volume, velocity, and variety \citep{laney20013d} as cited by \citep{landset2015survey}. Volume is the amount of data needed to process. Velocity is the speed at which the data can be evaluated. Finally, variety is the differences between types of data. This framework will be considered at least in part in evaluating fitness over the course of this project. 

The organization and implementation of linguistic analysis has always proven difficult for researchers. For instance, ambiguity in language requires special consideration \citep{bungum2010evolutionary}. Many traditional approaches result in statistical models with high dimensionality, resulting in a lack of applicability across languages or domain \citep{aghdam2009text}. On the other hand, linguistic models aiming for generalization are often overly broad, also resulting in low practical use \citep{nivre2015towards}. In evolutionary algorithm approaches, rule-based systems are often high quality, with lower applicability to different types of texts, while data-driven models tend to have high coverage across text sources, but lower quality of information \citep{bungum2010evolutionary}. Aghdam, et al. \citep{aghdam2009text} applied ant-colony optimization methods to explore a word space feature selection, particularly useful in defining a minimal subset with suitable accuracy, with fewer features in comparison to information gain and CHI methods. Due to the complexity of the task, in some cases, no method exists to assess the relationship between performance and parameters \citep{bungum2010evolutionary}. 

Though common in practice, when working with large datasets, repetitive manual adjustment is inefficient and unlikely to result in optimal results. Fine-tuning hyperparameters on various machine learning algorithms in textual data is particularly challenging, as the theoretical bases for natural language processing are still under debate and not fully developed. The application of evolutionary programming toward the language classification problem domain in order to optimize machine learning algorithms is a suitable target. As this project is exploratory, the eventual experimental design will consider and may incorporate multiple parameters associated with word classification and word discrimination. Schmidt \citep{schmidt2019performance} demonstrates the capacity of differential evolution in hypertuning parameters allowing for a multimodal design. That said, focus on tuning a single procedural step may be preferable, allowing for more trials and greater detail.

This project has the potential for supporting or challenging the linear discrimination approach proposed by \citep{baayen2019discriminative}. For instance, \citep{baayen2019discriminative} acknowledge that the application of a naïve Bayes classification model or neural network comparison may serve to supplement their findings. Alternatively, Lee, Lim, and Ahn \citep{lee2019automotive} suggest that graph-directed models may improve on tree-based models. \cite{gleim2019practitioner} assessed lemmatization comparing fine-grained parts of speech as opposed to coarser groups, a parameter with potential for optimization using genetic algorithms. \citep{baayen2019discriminative} and \citep{buchanan_dedeyne_montefinese_2019} used the tree-tagger library developed by Schmid \citep{schmid1994probabilistic, schmid1999improvements}. Though tree-tagger is common in research, the library is deserving of review as it is more well-suited to smaller datasets. Adjusting decision trees by applying genetic algorithms using a random forest model may increase performance or contribute to improvements in word classification, producing stop-words, spell-checking, parts of speech, and semantic meaning most closely approximating natural language processing. 

\section{Methods}

The project will be divided into two primary algorithm methodologies in evolutionary programming. Naive approaches evaluate textual data without context using clustering \citep{bungum2010evolutionary}. Probabilistic approaches are supervised methods using annotated data \citep{bungum2010evolutionary}. First, for an unsupervised approach, spectral clustering, agglomerative clustering with varying linkage criteria, and potentially affinity propagation will be applied. The ‘fitness’ of the clustering results will be determined using cluster coherency between actual labels among the clusters and cluster validation metrics proposed by Dr. Obafemi-Tayo. Second, for a supervised approach, Random Forest and Decision Trees will be used. The ‘fitness’ will be directly linked to the performance of these algorithms in terms of accuracy, and potentially F1-Score. The evolutionary approach can be explained with simplified steps of the entire process. Each algorithm previously mentioned will have its own structure for setting up the primary processes in evolutionary learning: parent selection, crossover, mutation, and survival selection. The population that will be used for each algorithm will be the corresponding hyperparameters associated with each algorithm. Ideal numerical ranges on certain hyperparameters will be determined by corresponding literature review, in order to not skew results. Results of the algorithms will be visualized in order to better perceive the progress of algorithms as the population and hyperparameters evolve. 

To showcase the design behind our project, we have selected a data set that is associated with one of the colleagues on the project. A large, robust dataset corresponding to complex word cues, associations, and varying associated features will be used. The data used are from \citep{buchanan_dedeyne_montefinese_2019} consisting of over 16,000 concept-feature responses. In a concept-feature task, respondents are provided with a cue consisting of a single word to which they are asked to provide a typed response. These responses were analyzed and nominally classified. Words were classified as part of speech, including adjectives, nouns, and verbs. These were further classified as either concrete or abstract terms. Concrete terms are more easily visualized and sensed, while abstract terms require more higher-order thinking. The process identifies stop words, generates lemmas, groups of words with properties in common. Relationship encoding is based on distance. Because the data has been processed and labeled, the set is well-suited for experimentation. Because the project is intended as a primer for individuals new to decision trees, a comparison analysis applying evolutionary algorithm methods would serve this purpose well.  

The population will consist of the cue words and associated relations between parts of speech, lemmas, with variation in hyperparameters and value ranges within the decision tree or alternative classification method. The dependent variables may include computational speed, cost, and either alignment or improvement upon preexisting models (such as a reduction in dimensionality). In order to implement this project, sci-kit learn \citep{pedregosa2011scikit}, NumPy \citep{oliphant2006guide}, and pandas \citep{mckinney2010data} will be the primary existing packages utilized. These libraries are open-source and well-established in literature. In order to represent the problem in code, we will use sci-kit learn to implement the various machine learning algorithms. Tree-tagger is an open-source decision-tree library commonly used for lemmatization including annotation and part of speech classification. A critical assessment of the parameters used in tree-tagger is a suitable target for improvement. The hyperparameters of the algorithms used my serve as the population to be optimized. This will be represented by a list of numbers and strings, where each index in the list will represent its corresponding hyperparameter.  

As a means to evaluate the child population for comparison with an existing created population, a simple evaluation with low overhead will be developed using an accuracy metric in which we measure how well each machine learning algorithm performs in terms of accurately classifying a sample with the specified hyperparameters. Accuracy, feature importance, practical application, and computational complexity will be considered in the fitness of the results. 



\section{Results and Discussion}

\section{Conclusion}

\bibliographystyle{plain}
\bibliography{references}
\end{document}
